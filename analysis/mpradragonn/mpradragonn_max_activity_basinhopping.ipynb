{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential, Model, load_model\n",
    "\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Input, Lambda\n",
    "from keras.layers import Conv2D, MaxPooling2D, Conv1D, MaxPooling1D, LSTM, ConvLSTM2D, GRU, BatchNormalization, LocallyConnected2D, Permute\n",
    "from keras.layers import Concatenate, Reshape, Softmax, Conv2DTranspose, Embedding, Multiply\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, Callback\n",
    "from keras import regularizers\n",
    "from keras import backend as K\n",
    "import keras.losses\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops\n",
    "\n",
    "import isolearn.keras as iso\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "import logging\n",
    "logging.getLogger('tensorflow').setLevel(logging.ERROR)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "import scipy.sparse as sp\n",
    "import scipy.io as spio\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import isolearn.io as isoio\n",
    "import isolearn.keras as isol\n",
    "\n",
    "from genesis.visualization import *\n",
    "from genesis.generator import *\n",
    "from genesis.predictor import *\n",
    "from genesis.optimizer import *\n",
    "\n",
    "import sklearn\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from matplotlib import colors\n",
    "\n",
    "from scipy.optimize import basinhopping, OptimizeResult\n",
    "\n",
    "class IdentityEncoder(iso.SequenceEncoder) :\n",
    "    \n",
    "    def __init__(self, seq_len, channel_map) :\n",
    "        super(IdentityEncoder, self).__init__('identity', (seq_len, len(channel_map)))\n",
    "        \n",
    "        self.seq_len = seq_len\n",
    "        self.n_channels = len(channel_map)\n",
    "        self.encode_map = channel_map\n",
    "        self.decode_map = {\n",
    "            nt: ix for ix, nt in self.encode_map.items()\n",
    "        }\n",
    "    \n",
    "    def encode(self, seq) :\n",
    "        encoding = np.zeros((self.seq_len, self.n_channels))\n",
    "        \n",
    "        for i in range(len(seq)) :\n",
    "            if seq[i] in self.encode_map :\n",
    "                channel_ix = self.encode_map[seq[i]]\n",
    "                encoding[i, channel_ix] = 1.\n",
    "\n",
    "        return encoding\n",
    "    \n",
    "    def encode_inplace(self, seq, encoding) :\n",
    "        for i in range(len(seq)) :\n",
    "            if seq[i] in self.encode_map :\n",
    "                channel_ix = self.encode_map[seq[i]]\n",
    "                encoding[i, channel_ix] = 1.\n",
    "    \n",
    "    def encode_inplace_sparse(self, seq, encoding_mat, row_index) :\n",
    "        raise NotImplementError()\n",
    "    \n",
    "    def decode(self, encoding) :\n",
    "        seq = ''\n",
    "    \n",
    "        for pos in range(0, encoding.shape[0]) :\n",
    "            argmax_nt = np.argmax(encoding[pos, :])\n",
    "            max_nt = np.max(encoding[pos, :])\n",
    "            seq += self.decode_map[argmax_nt]\n",
    "\n",
    "        return seq\n",
    "    \n",
    "    def decode_sparse(self, encoding_mat, row_index) :\n",
    "        raise NotImplementError()\n",
    "\n",
    "def load_predictor_model(model_path) :\n",
    "\n",
    "    saved_model = Sequential()\n",
    "\n",
    "    # sublayer 1\n",
    "    saved_model.add(Conv1D(48, 3, padding='same', activation='relu', input_shape=(145, 4), name='dragonn_conv1d_1_copy'))\n",
    "    saved_model.add(BatchNormalization(name='dragonn_batchnorm_1_copy'))\n",
    "    saved_model.add(Dropout(0.1, name='dragonn_dropout_1_copy'))\n",
    "\n",
    "    saved_model.add(Conv1D(64, 3, padding='same', activation='relu', name='dragonn_conv1d_2_copy'))\n",
    "    saved_model.add(BatchNormalization(name='dragonn_batchnorm_2_copy'))\n",
    "    saved_model.add(Dropout(0.1, name='dragonn_dropout_2_copy'))\n",
    "\n",
    "    saved_model.add(Conv1D(100, 3, padding='same', activation='relu', name='dragonn_conv1d_3_copy'))\n",
    "    saved_model.add(BatchNormalization(name='dragonn_batchnorm_3_copy'))\n",
    "    saved_model.add(Dropout(0.1, name='dragonn_dropout_3_copy'))\n",
    "\n",
    "    saved_model.add(Conv1D(150, 7, padding='same', activation='relu', name='dragonn_conv1d_4_copy'))\n",
    "    saved_model.add(BatchNormalization(name='dragonn_batchnorm_4_copy'))\n",
    "    saved_model.add(Dropout(0.1, name='dragonn_dropout_4_copy'))\n",
    "\n",
    "    saved_model.add(Conv1D(300, 7, padding='same', activation='relu', name='dragonn_conv1d_5_copy'))\n",
    "    saved_model.add(BatchNormalization(name='dragonn_batchnorm_5_copy'))\n",
    "    saved_model.add(Dropout(0.1, name='dragonn_dropout_5_copy'))\n",
    "\n",
    "    saved_model.add(MaxPooling1D(3))\n",
    "\n",
    "    # sublayer 2\n",
    "    saved_model.add(Conv1D(200, 7, padding='same', activation='relu', name='dragonn_conv1d_6_copy'))\n",
    "    saved_model.add(BatchNormalization(name='dragonn_batchnorm_6_copy'))\n",
    "    saved_model.add(Dropout(0.1, name='dragonn_dropout_6_copy'))\n",
    "\n",
    "    saved_model.add(Conv1D(200, 3, padding='same', activation='relu', name='dragonn_conv1d_7_copy'))\n",
    "    saved_model.add(BatchNormalization(name='dragonn_batchnorm_7_copy'))\n",
    "    saved_model.add(Dropout(0.1, name='dragonn_dropout_7_copy'))\n",
    "\n",
    "    saved_model.add(Conv1D(200, 3, padding='same', activation='relu', name='dragonn_conv1d_8_copy'))\n",
    "    saved_model.add(BatchNormalization(name='dragonn_batchnorm_8_copy'))\n",
    "    saved_model.add(Dropout(0.1, name='dragonn_dropout_8_copy'))\n",
    "\n",
    "    saved_model.add(MaxPooling1D(4))\n",
    "\n",
    "    # sublayer 3\n",
    "    saved_model.add(Conv1D(200, 7, padding='same', activation='relu', name='dragonn_conv1d_9_copy'))\n",
    "    saved_model.add(BatchNormalization(name='dragonn_batchnorm_9_copy'))\n",
    "    saved_model.add(Dropout(0.1, name='dragonn_dropout_9_copy'))\n",
    "\n",
    "    saved_model.add(MaxPooling1D(4))\n",
    "\n",
    "    saved_model.add(Flatten())\n",
    "    saved_model.add(Dense(100, activation='relu', name='dragonn_dense_1_copy'))\n",
    "    saved_model.add(BatchNormalization(name='dragonn_batchnorm_10_copy'))\n",
    "    saved_model.add(Dropout(0.1, name='dragonn_dropout_10_copy'))\n",
    "    saved_model.add(Dense(12, activation='linear', name='dragonn_dense_2_copy'))\n",
    "\n",
    "    saved_model.compile(\n",
    "        loss= \"mean_squared_error\",\n",
    "        optimizer=keras.optimizers.SGD(lr=0.1)\n",
    "    )\n",
    "\n",
    "    saved_model.load_weights(model_path)\n",
    "    \n",
    "    return saved_model\n",
    "\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "\n",
    "def contain_tf_gpu_mem_usage() :\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True\n",
    "    sess = tf.Session(config=config)\n",
    "    set_session(sess)\n",
    "\n",
    "contain_tf_gpu_mem_usage()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Specfiy file path to pre-trained predictor network\n",
    "\n",
    "saved_predictor_model_path = '../../../seqprop/examples/mpradragonn/pretrained_deep_factorized_model.hdf5'\n",
    "\n",
    "saved_predictor = load_predictor_model(saved_predictor_model_path)\n",
    "\n",
    "acgt_encoder = IdentityEncoder(145, {'A':0, 'C':1, 'G':2, 'T':3})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def _store_sequence(run_dir, run_prefix, seq, curr_iter) :\n",
    "    #Save sequence to file\n",
    "    with open(run_dir + run_prefix + \"_iter_\" + str(int(curr_iter)) + \".txt\", \"a+\") as f :\n",
    "        f.write(seq + \"\\n\")\n",
    "\n",
    "def get_step_func(predictor, sequence_template, acgt_encoder) :\n",
    "    \n",
    "    available_positions = [\n",
    "        j for j in range(len(sequence_template)) if sequence_template[j] == 'N'\n",
    "    ]\n",
    "    \n",
    "    available_nt_dict = {\n",
    "        0 : [1, 2, 3],\n",
    "        1 : [0, 2, 3],\n",
    "        2 : [1, 0, 3],\n",
    "        3 : [1, 2, 0]\n",
    "    }\n",
    "        \n",
    "    _predict_func = get_predict_func(predictor, len(sequence_template))\n",
    "    \n",
    "    def _step_func(x, sequence_template=sequence_template, available_positions=available_positions, available_nt_dict=available_nt_dict) :\n",
    "        \n",
    "        onehot = np.expand_dims(np.expand_dims(x.reshape((len(sequence_template), 4)), axis=0), axis=-1)\n",
    "        \n",
    "        #Choose random position and nucleotide identity\n",
    "        rand_pos = np.random.choice(available_positions)\n",
    "        \n",
    "        curr_nt = np.argmax(onehot[0, rand_pos, :, 0])\n",
    "        rand_nt = np.random.choice(available_nt_dict[curr_nt])\n",
    "        \n",
    "        #Swap nucleotides\n",
    "        onehot[0, rand_pos, :, 0] = 0.\n",
    "        onehot[0, rand_pos, rand_nt, 0] = 1.\n",
    "        \n",
    "        new_x = np.ravel(onehot)\n",
    "        \n",
    "        return new_x\n",
    "    \n",
    "    return _step_func\n",
    "\n",
    "def get_predict_func(predictor, seq_len) :\n",
    "    \n",
    "    def _predict_func(x, predictor=predictor, seq_len=seq_len) :\n",
    "        \n",
    "        onehot = np.expand_dims(x.reshape((seq_len, 4)), axis=0)\n",
    "        \n",
    "        score_pred = predictor.predict(x=[onehot], batch_size=1)\n",
    "        score_pred = score_pred[0, 5]\n",
    "\n",
    "        return -score_pred\n",
    "    \n",
    "    return _predict_func\n",
    "\n",
    "def run_simulated_annealing(run_prefix, predictor, sequence_template, acgt_encoder, n_iters=1000, n_iters_per_temperate=100, temperature_init=1.0, temperature_func=None, verbose=False) :\n",
    "    \n",
    "    run_dir = \"./samples/\" + run_prefix + \"/\"\n",
    "    run_prefix = \"intermediate\"\n",
    "    \n",
    "    if not os.path.exists(run_dir): os.makedirs(run_dir)\n",
    "    \n",
    "    if temperature_func is None :\n",
    "        temperature_func = lambda t, curr_iter, t_init=temperature_init, total_iters=n_iters: t\n",
    "    \n",
    "    n_epochs = n_iters // n_iters_per_temperate\n",
    "    \n",
    "    predict_func = get_predict_func(predictor, len(sequence_template))\n",
    "    step_func = get_step_func(predictor, sequence_template, acgt_encoder)\n",
    "    \n",
    "    #Random initialization\n",
    "    random_sequence = ''.join([\n",
    "        sequence_template[j] if sequence_template[j] != 'N' else np.random.choice(['A', 'C', 'G', 'T'])\n",
    "        for j in range(len(sequence_template))\n",
    "    ])\n",
    "\n",
    "    x0 = np.ravel(acgt_encoder.encode(random_sequence))\n",
    "    \n",
    "    x = x0\n",
    "    temperature = temperature_init\n",
    "    \n",
    "    seq_opt = \"\"\n",
    "    tracked_scores = [predict_func(x)]\n",
    "    for epoch_ix in range(n_epochs) :\n",
    "        \n",
    "        x_opt, f_opt = run_basinhopping(x, predict_func, step_func, n_iters=n_iters_per_temperate, temperature=temperature)\n",
    "    \n",
    "        onehot_opt = np.expand_dims(np.expand_dims(x_opt.reshape((len(sequence_template), 4)), axis=0), axis=-1)\n",
    "\n",
    "        seq_opt = acgt_encoder.decode(onehot_opt[0, :, :, 0])\n",
    "        score_opt = -f_opt\n",
    "        tracked_scores.append(score_opt)\n",
    "        \n",
    "        if verbose :\n",
    "            print(\"Iter \" + str((epoch_ix + 1) * n_iters_per_temperate) + \", Temp = \" + str(round(temperature, 4)) + \", Score = \" + str(round(score_opt, 4)) + \"...\")\n",
    "\n",
    "        _store_sequence(run_dir, run_prefix, seq_opt, (epoch_ix + 1) * n_iters_per_temperate)\n",
    "        \n",
    "        x = x_opt\n",
    "        temperature = temperature_func(temperature, (epoch_ix + 1) * n_iters_per_temperate)\n",
    "    \n",
    "    return seq_opt, np.array(tracked_scores)\n",
    "        \n",
    "        \n",
    "def run_basinhopping(x, predict_func, step_func, n_iters=1000, temperature=1.0) :\n",
    "    \n",
    "    def _dummy_min_opt(fun, x0, args=(), **options) :\n",
    "        return OptimizeResult(fun=fun(x0), x=x0, nit=0, nfev=0, success=True)\n",
    "    \n",
    "    minimizer_kwargs = {\n",
    "        'method' : _dummy_min_opt,\n",
    "        'options' : { 'maxiter' : 0 }\n",
    "    }\n",
    "    \n",
    "    opt_res = basinhopping(predict_func, x, minimizer_kwargs=minimizer_kwargs, stepsize=None, niter=n_iters, T=temperature, take_step=step_func)\n",
    "    \n",
    "    return opt_res.x, opt_res.fun\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Run the basinhopping algorithm\n",
    "\n",
    "run_prefix = \"basinhopping_mpradragonn_max_activity_1000_iters\"\n",
    "\n",
    "sequence_template = 'N' * 145\n",
    "\n",
    "n_sequences = 4096\n",
    "n_iters = 1000\n",
    "n_iters_per_temperate = 100\n",
    "\n",
    "verbose = False\n",
    "\n",
    "t_init = 0.1\n",
    "t_func = lambda t, curr_iter, t_init=t_init, total_iters=n_iters, t_min=0.05, exp_scale=1./0.7: t_init * t_min**(min(float(curr_iter / total_iters) * exp_scale, 1.0))\n",
    "\n",
    "f = plt.figure(figsize=(6, 4))\n",
    "\n",
    "it_space = [0] + [(epoch_ix + 1) * n_iters_per_temperate for epoch_ix in range(n_iters // n_iters_per_temperate)]\n",
    "temp = t_init\n",
    "temp_space = [temp]\n",
    "for j in range(1, len(it_space)) :\n",
    "    it = it_space[j]\n",
    "    temp = t_func(temp, it)\n",
    "    temp_space.append(temp)\n",
    "\n",
    "plt.plot(it_space, temp_space, linewidth=2, color='black', linestyle='-')\n",
    "\n",
    "plt.xlabel(\"Iteration\", fontsize=14)\n",
    "plt.ylabel(\"Temperature\", fontsize=14)\n",
    "plt.title(\"Anneal schedule\", fontsize=14)\n",
    "\n",
    "plt.xlim(0, np.max(it_space))\n",
    "\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "optimized_seqs = []\n",
    "optimized_trajs = []\n",
    "for sequence_ix in range(n_sequences) :\n",
    "    \n",
    "    seq, scores = run_simulated_annealing(run_prefix, saved_predictor, sequence_template, acgt_encoder, n_iters=n_iters, n_iters_per_temperate=n_iters_per_temperate, temperature_init=t_init, temperature_func=t_func, verbose=verbose)\n",
    "    \n",
    "    if sequence_ix % 100 == 0 :\n",
    "        print(\"Optimized sequence \" + str(sequence_ix) + \". Score = \" + str(round(scores[-1], 4)))\n",
    "    \n",
    "    optimized_seqs.append(seq)\n",
    "    optimized_trajs.append(scores.reshape(1, -1))\n",
    "\n",
    "optimized_trajs = np.concatenate(optimized_trajs, axis=0)\n",
    "\n",
    "print(\"Finished optimizing \" + str(optimized_trajs.shape[0]) + \" sequences.\")\n",
    "\n",
    "plot_n_trajs = min(optimized_trajs.shape[0], 500)\n",
    "\n",
    "f = plt.figure(figsize=(6, 4))\n",
    "\n",
    "it_space = [0] + [(epoch_ix + 1) * n_iters_per_temperate for epoch_ix in range(n_iters // n_iters_per_temperate)]\n",
    "\n",
    "for i in range(plot_n_trajs) :\n",
    "    plt.plot(it_space, optimized_trajs[i, :], linewidth=2, linestyle='-')\n",
    "\n",
    "plt.xlabel(\"Iteration\", fontsize=14)\n",
    "plt.ylabel(\"Fitness Score\", fontsize=14)\n",
    "plt.title(\"Anneal sequence results\", fontsize=14)\n",
    "\n",
    "plt.xlim(0, np.max(it_space))\n",
    "\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Save sequences to file\n",
    "with open(run_prefix + \"_4096_sequences.txt\", \"wt\") as f:\n",
    "    for i in range(len(optimized_seqs)) :\n",
    "        f.write(optimized_seqs[i] + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
